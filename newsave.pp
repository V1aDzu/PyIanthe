–§—É–Ω–∫—Ü–∏—è –ü–û–õ–ù–û–ì–û –∞–≤–∞—Ä–∏–π–Ω–æ–≥–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è (–ö–õ–Æ–ß–ï–í–û–ï)
–ß—Ç–æ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ model/
model/
‚îú‚îÄ‚îÄ model.safetensors
‚îú‚îÄ‚îÄ config.json
‚îú‚îÄ‚îÄ tokenizer/
‚îú‚îÄ‚îÄ training_state.json        ‚Üê –ù–ê–® —Ñ–∞–π–ª
‚îú‚îÄ‚îÄ optimizer.pt               ‚Üê –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ
‚îú‚îÄ‚îÄ scheduler.pt               ‚Üê –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ
‚îú‚îÄ‚îÄ scaler.pt                  ‚Üê –µ—Å–ª–∏ fp16
‚îú‚îÄ‚îÄ rng_state.pth

–ü—Ä–∏–º–µ—Ä —Ñ—É–Ω–∫—Ü–∏–∏
def emergency_full_save(model, tokenizer, trainer, output_dir):
    os.makedirs(output_dir, exist_ok=True)

    # 1. –ú–æ–¥–µ–ª—å + —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä
    model.save_pretrained(output_dir)
    tokenizer.save_pretrained(output_dir)

    # 2. RNG
    torch.save({
        "torch": torch.get_rng_state(),
        "cuda": torch.cuda.get_rng_state_all() if torch.cuda.is_available() else None,
    }, os.path.join(output_dir, "rng_state.pth"))

    # 3. Optimizer / Scheduler / Scaler (–µ—Å–ª–∏ –µ—Å—Ç—å)
    if trainer.optimizer:
        torch.save(trainer.optimizer.state_dict(),
                   os.path.join(output_dir, "optimizer.pt"))

    if trainer.lr_scheduler:
        torch.save(trainer.lr_scheduler.state_dict(),
                   os.path.join(output_dir, "scheduler.pt"))

    if hasattr(trainer, "scaler") and trainer.scaler:
        torch.save(trainer.scaler.state_dict(),
                   os.path.join(output_dir, "scaler.pt"))

    # 4. –ù–ê–® state (–Ω–µ HF)
    state = {
        "global_step": trainer.state.global_step,
        "epoch": float(trainer.state.epoch or 0),
        "saved_at": datetime.now().isoformat(),
    }

    with open(os.path.join(output_dir, "training_state.json"), "w") as f:
        json.dump(state, f, indent=2)


‚ùó –≠—Ç–æ –Ω–µ HF checkpoint. –≠—Ç–æ —Ç–≤–æ–π –∞—Ç–æ–º–∞—Ä–Ω—ã–π snapshot.

2Ô∏è‚É£ –ö–∞–∫ –í–û–°–°–¢–ê–ù–ê–í–õ–ò–í–ê–¢–¨–°–Ø (–≥–∏–±–∫–æ!)
def load_soft_resume(model_dir, model, trainer):
    state_file = os.path.join(model_dir, "training_state.json")
    if not os.path.exists(state_file):
        return 0

    with open(state_file) as f:
        state = json.load(f)

    # optimizer ‚Äî –¢–û–õ–¨–ö–û –µ—Å–ª–∏ —Ç—ã —Ö–æ—á–µ—à—å
    opt_path = os.path.join(model_dir, "optimizer.pt")
    if os.path.exists(opt_path) and trainer.optimizer:
        trainer.optimizer.load_state_dict(torch.load(opt_path))

    # scheduler ‚Äî –¢–û–õ–¨–ö–û –µ—Å–ª–∏ —Å–æ–≤–º–µ—Å—Ç–∏–º
    sch_path = os.path.join(model_dir, "scheduler.pt")
    if os.path.exists(sch_path) and trainer.lr_scheduler:
        trainer.lr_scheduler.load_state_dict(torch.load(sch_path))

    # scaler
    scaler_path = os.path.join(model_dir, "scaler.pt")
    if os.path.exists(scaler_path) and hasattr(trainer, "scaler"):
        trainer.scaler.load_state_dict(torch.load(scaler_path))

    return state["global_step"]

    –û—Ç–∫–ª—é—á–∞–µ–º HF-—á–µ–∫–ø–æ–∏–Ω—Ç—ã –∫–∞–∫ –º–µ—Ö–∞–Ω–∏–∑–º –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è
‚ùå –£–ë–†–ê–¢–¨ –ø–æ–ª–Ω–æ—Å—Ç—å—é
last_checkpoint = get_last_checkpoint()
resume_from = last_checkpoint


–ò –≤—Å—é –ª–æ–≥–∏–∫—É:

resume_from_checkpoint=resume_from


HF checkpoint –±–æ–ª—å—à–µ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è resume.

2Ô∏è‚É£ –£–ø—Ä–æ—â–∞–µ–º –∑–∞–≥—Ä—É–∑–∫—É –º–æ–¥–µ–ª–∏ (–∫–ª—é—á–µ–≤–æ–µ –º–µ—Å—Ç–æ)
üîÅ –ó–ê–ú–ï–ù–ò–¢–¨ –ë–õ–û–ö –ó–ê–ì–†–£–ó–ö–ò –ú–û–î–ï–õ–ò –ù–ê –≠–¢–û
MODEL_STATE_DIR = MAIN_MODEL_DIR

if os.path.exists(os.path.join(MODEL_STATE_DIR, "model.safetensors")):
    logger.info(f"–ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –º–æ–¥–µ–ª—å –∑: {MODEL_STATE_DIR}")

    model = AutoModelForCausalLM.from_pretrained(
        MODEL_STATE_DIR,
        local_files_only=True,
        attn_implementation=attn_impl
    ).to(device)

    tokenizer = AutoTokenizer.from_pretrained(
        MODEL_STATE_DIR,
        local_files_only=True
    )

else:
    logger.info("–ú–æ–¥–µ–ª—å –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–∞ ‚Äî —Å—Ç–≤–æ—Ä—é—î–º–æ –Ω–æ–≤—É")

    config = GPT2Config(
        vocab_size=len(tokenizer),
        n_positions=CONTEXT_LENGTH,
        n_ctx=CONTEXT_LENGTH,
        n_embd=pyIanthe_config.EMBEDDING_DIM,
        n_layer=pyIanthe_config.NUM_LAYERS,
        n_head=pyIanthe_config.HEADS,
        use_cache=False,
        pad_token_id=tokenizer.eos_token_id,
        tie_word_embeddings=True,
    )

    model = AutoModelForCausalLM.from_config(
        config,
        attn_implementation=attn_impl
    ).to(device)


‚ùó –ù–ò–ö–ê–ö–ò–• resume_from_checkpoint

3Ô∏è‚É£ TrainingArguments ‚Äî —Ç–æ–ª—å–∫–æ –∏–∑ —Ç–µ–∫—É—â–µ–≥–æ –∫–æ–Ω—Ñ–∏–≥–∞

–≠—Ç–æ —É–∂–µ –ø–æ—á—Ç–∏ –ø—Ä–∞–≤–∏–ª—å–Ω–æ, –Ω–æ –Ω–∞–¥–æ —É–±—Ä–∞—Ç—å –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å –æ—Ç —Å—Ç–∞—Ä–æ–≥–æ state.

‚ùó –ò–ó–ú–ï–ù–ò–¢–¨
training_args = TrainingArguments(
    output_dir=CHECKPOINT_DIR,
    overwrite_output_dir=True,  # –≤–∞–∂–Ω–æ
    num_train_epochs=1,
    save_steps=SAVE_STEPS,
    save_strategy="steps",
    save_total_limit=pyIanthe_config.SAVE_LIMIT,
    logging_steps=100,
    learning_rate=LEARNING_RATE,
    ...
)


HF –º–æ–∂–µ—Ç —Å–æ—Ö—Ä–∞–Ω—è—Ç—å, –Ω–æ –º—ã –ù–ï –∏—Å–ø–æ–ª—å–∑—É–µ–º —ç—Ç–æ –¥–ª—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è.

4Ô∏è‚É£ –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è EMERGENCY SAVE (–∫–ª—é—á–µ–≤–∞—è —á–∞—Å—Ç—å)
üî• –î–û–ë–ê–í–¨ –≠–¢–£ –§–£–ù–ö–¶–ò–Æ
def emergency_full_save(model, tokenizer, trainer, target_dir):
    logger.warning("‚ö† EMERGENCY SAVE: –∑–±–µ—Ä—ñ–≥–∞—î–º–æ –ü–û–í–ù–ò–ô —Å—Ç–∞–Ω")

    tmp_dir = target_dir + "_tmp"
    os.makedirs(tmp_dir, exist_ok=True)

    model.save_pretrained(tmp_dir)
    tokenizer.save_pretrained(tmp_dir)

    torch.save(trainer.optimizer.state_dict(), os.path.join(tmp_dir, "optimizer.pt"))
    torch.save(trainer.lr_scheduler.state_dict(), os.path.join(tmp_dir, "scheduler.pt"))

    with open(os.path.join(tmp_dir, "trainer_meta.json"), "w") as f:
        json.dump({
            "global_step": trainer.state.global_step,
            "epoch": trainer.state.epoch,
        }, f, indent=2)

    # –∞—Ç–æ–º–∞—Ä–Ω–∞—è –∑–∞–º–µ–Ω–∞
    if os.path.exists(target_dir):
        shutil.rmtree(target_dir)
    os.rename(tmp_dir, target_dir)

    logger.warning(f"‚úì Emergency save complete ‚Üí {target_dir}")

5Ô∏è‚É£ KeyboardInterrupt ‚Äî –ü–†–ê–í–ò–õ–¨–ù–û
üîÅ –ó–ê–ú–ï–ù–ò –í–ï–°–¨ except KeyboardInterrupt –ù–ê:
except KeyboardInterrupt:
    logger.error("‚ö° –ê–í–ê–†–Ü–ô–ù–ï –ü–ï–†–ï–†–ò–í–ê–ù–ù–Ø (–Ω–µ–º–∞—î —Å–≤—ñ—Ç–ª–∞ / Ctrl+C)")

    emergency_full_save(
        model=model,
        tokenizer=tokenizer,
        trainer=trainer,
        target_dir=MAIN_MODEL_DIR
    )

    sys.exit(0)


‚ùó –ù–ò–ö–ê–ö–ò–• trainer.save_state()
‚ùó –ù–ò–ö–ê–ö–ò–• –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–π –∏–∑ CHECKPOINT_DIR

6Ô∏è‚É£ –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –ø–æ—Å–ª–µ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞ (–∫–∞–∫ —ç—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç)

–°–≤–µ—Ç –ø—Ä–æ–ø–∞–ª ‚Üí emergency save

–°–≤–µ—Ç –ø–æ—è–≤–∏–ª—Å—è ‚Üí —Ç—ã:

–º–µ–Ω—è–µ—à—å LEARNING_RATE

–º–µ–Ω—è–µ—à—å GRADIENT_ACCUMULATION_STEPS

–º–µ–Ω—è–µ—à—å —á—Ç–æ —É–≥–æ–¥–Ω–æ

–ó–∞–ø—É—Å–∫ —Å–∫—Ä–∏–ø—Ç–∞:

–º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è

optimizer —Å–æ–∑–¥–∞—ë—Ç—Å—è –∑–∞–Ω–æ–≤–æ

scheduler —Å–æ–∑–¥–∞—ë—Ç—Å—è –∑–∞–Ω–æ–≤–æ

–æ–±—É—á–µ–Ω–∏–µ –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç—Å—è —Å—Ç–∞–±–∏–ª—å–Ω–æ

–î–∞, LR ¬´—Å–∫–∞–∫–Ω—ë—Ç¬ª ‚Äî –∏ —ç—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ, —Ç—ã —Å–∞–º —ç—Ç–æ–≥–æ —Ö–æ—á–µ—à—å.